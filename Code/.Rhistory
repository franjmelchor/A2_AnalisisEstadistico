rhs = labels(rhs(rules)),
rules@quality)
ruledf$confidence_percent <- round(ruledf$confidence*100, digits = 2)
ruledf$support_percent <- round(ruledf$support*100, digits = 2)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_primer_contrato.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = NA
)
library (arules)
origen = read.csv(
"D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/ml_categorization_190509.csv",
header = TRUE,
sep = "|",
colClasses = "factor"
)
# Drop columns:
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
x_no_hay_registro_de_localidad_centro,
porcentaje_tiempo_trabajado_desde_16_years_intervalo
)
)
colnames(data)
# Prepare values =N to be rejected by arules (appearance-> none from apriori)
negative_values = c()
for (col_name in colnames(data)) {
if(
col_name != "genero"
&& col_name != "edad_rango"
&& col_name != "num_estudios_basicos"
&& col_name != "num_estudios_universitarios"
&& col_name != "porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo"
){
negative_values <- c(negative_values, paste0(col_name,"=N"))
}
}
rules <- apriori(data,
parameter = list(
minlen = 2,
maxlen = 5,
supp = 0.00001,
conf = 0.6,
target="rules",
maxtime = 0
),
appearance = list(
none = negative_values,
default = "lhs",
rhs = c(
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=_NO HAY REGISTRO DE CONTRATOS",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=<30%",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=30%-70%",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=>70%"
)
)
)
rules <- sort(rules, by="confidence", decreasing=TRUE)
ruledf = data.frame(
lhs = labels(lhs(rules)),
rhs = labels(rhs(rules)),
rules@quality)
ruledf$confidence_percent <- round(ruledf$confidence*100, digits = 2)
ruledf$support_percent <- round(ruledf$support*100, digits = 2)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_primer_contrato.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = NA
)
library (arules)
origen = read.csv(
"D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/ml_categorization_190509.csv",
header = TRUE,
sep = "|",
colClasses = "factor"
)
# Drop columns:
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
x_no_hay_registro_de_localidad_centro,
porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo
)
)
# Prepare values =N to be rejected by arules (appearance-> none from apriori)
negative_values = c()
for (col_name in colnames(data)) {
if(
col_name != "genero"
&& col_name != "edad_rango"
&& col_name != "num_estudios_basicos"
&& col_name != "num_estudios_universitarios"
&& col_name != "porcentaje_tiempo_trabajado_desde_16_years_intervalo"
){
negative_values <- c(negative_values, paste0(col_name,"=N"))
}
}
rules <- apriori(data,
parameter = list(
minlen = 2,
maxlen = 5,
supp = 0.00001,
conf = 0.6,
target="rules",
maxtime = 0
),
appearance = list(
none = negative_values,
default = "lhs",
rhs = c(
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=_NO HAY REGISTRO DE CONTRATOS",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=<30%",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=30%-70%",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=>70%"
)
)
)
rules <- sort(rules, by="confidence", decreasing=TRUE)
ruledf = data.frame(
lhs = labels(lhs(rules)),
rhs = labels(rhs(rules)),
rules@quality)
ruledf$confidence_percent <- round(ruledf$confidence*100, digits = 2)
ruledf$support_percent <- round(ruledf$support*100, digits = 2)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_16_anios.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = NA
)
memory.limit()
memory.limit()
aux = memory.limit()
aux
memory.limit(size=2500)
memory.limit(size=2500)
memory.limit(size=250000)
memory.limit(size=2500000000000)
memory.limit(size=250000000000000000000000000000000000000000000000000000000000)
memory.limit(size=25000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000000)
memory.limit(size=1)
memory.limit()
aux
round(memory.limit()/2^20, 2)
gc
gc()
library (arules)
origen = read.csv(
"D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/ml_categorization_190509.csv",
header = TRUE,
sep = "|",
colClasses = "factor"
)
# Drop columns:
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
x_no_hay_registro_de_localidad_centro,
porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo
)
)
# Prepare values =N to be rejected by arules (appearance-> none from apriori)
negative_values = c()
for (col_name in colnames(data)) {
if(
col_name != "genero"
&& col_name != "edad_rango"
&& col_name != "num_estudios_basicos"
&& col_name != "num_estudios_universitarios"
&& col_name != "porcentaje_tiempo_trabajado_desde_16_years_intervalo"
){
negative_values <- c(negative_values, paste0(col_name,"=N"))
}
}
gc()
rules <- apriori(data,
parameter = list(
minlen = 2,
maxlen = 5,
supp = 0.00001,
conf = 0.6,
target="rules",
maxtime = 0
),
appearance = list(
none = negative_values,
default = "lhs",
rhs = c(
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=_NO HAY REGISTRO DE CONTRATOS",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=<30%",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=30%-70%",
"porcentaje_tiempo_trabajado_desde_16_years_intervalo=>70%"
)
)
)
rules <- sort(rules, by="confidence", decreasing=TRUE)
ruledf = data.frame(
lhs = labels(lhs(rules)),
rhs = labels(rhs(rules)),
rules@quality)
ruledf$confidence_percent <- round(ruledf$confidence*100, digits = 2)
ruledf$support_percent <- round(ruledf$support*100, digits = 2)
gc()
size
size(data)
View(data)
origen = ''
memory.limit(size=10000)
library (arules)
origen = read.csv(
"D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/ml_categorization_190509.csv",
header = TRUE,
sep = "|",
colClasses = "factor"
)
# Drop columns:
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
x_no_hay_registro_de_localidad_centro,
x_no_hay_registro_de_centro,
porcentaje_tiempo_trabajado_desde_16_years_intervalo
)
)
# Prepare values =N to be rejected by arules (appearance-> none from apriori)
negative_values = c()
for (col_name in colnames(data)) {
if(
col_name != "genero"
&& col_name != "edad_rango"
&& col_name != "num_estudios_basicos"
&& col_name != "num_estudios_universitarios"
&& col_name != "porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo"
){
negative_values <- c(negative_values, paste0(col_name,"=N"))
}
}
rules <-
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
loc_x_no_hay_registro_de_localidad_centro,
centro_x_no_hay_registro_de_centro,
porcentaje_tiempo_trabajado_desde_16_years_intervalo
)
)
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
loc_x_no_hay_registro_de_localidad_centro,
centro_x_no_hay_registro_de_centro,
porcentaje_tiempo_trabajado_desde_16_years_intervalo
)
)
memory.limit(size=10000)
library (arules)
origen = read.csv(
"D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/ml_categorization_190509.csv",
header = TRUE,
sep = "|",
colClasses = "factor"
)
# Drop columns:
data = subset(origen,
select = -c(
dni,
x_no_hay_registro_de_titulacion_basica,
x_no_hay_registro_de_tipo_estudio_basico,
loc_x_no_hay_registro_de_localidad_centro,
centro_x_no_hay_registro_de_centro,
porcentaje_tiempo_trabajado_desde_16_years_intervalo
)
)
# Prepare values =N to be rejected by arules (appearance-> none from apriori)
negative_values = c()
for (col_name in colnames(data)) {
if(
col_name != "genero"
&& col_name != "edad_rango"
&& col_name != "num_estudios_basicos"
&& col_name != "num_estudios_universitarios"
&& col_name != "porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo"
){
negative_values <- c(negative_values, paste0(col_name,"=N"))
}
}
rules <- apriori(data,
parameter = list(
minlen = 2,
maxlen = 5,
supp = 0.00001,
conf = 0.6,
target="rules",
maxtime = 0
),
appearance = list(
none = negative_values,
default = "lhs",
rhs = c(
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=_NO HAY REGISTRO DE CONTRATOS",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=<30%",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=30%-70%",
"porcentaje_tiempo_trabajado_desde_primer_contrato_intervalo=>70%"
)
)
)
rules <- sort(rules, by="confidence", decreasing=TRUE)
ruledf = data.frame(
lhs = labels(lhs(rules)),
rhs = labels(rhs(rules)),
rules@quality)
ruledf$confidence_percent <- round(ruledf$confidence*100, digits = 2)
ruledf$support_percent <- round(ruledf$support*100, digits = 2)
names(ruledf)
ruledf
names(ruledf)[0]
names(ruledf)[1]
help(write)
help(write.table)
help(write.table)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_primer_contrato.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = 'a'
)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_primer_contrato.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = TRUE
)
write.table(
ruledf,
file = "D:/PRI_GEOTIME_BROKER/Machine Learning/arules/histarules/src/histarules/output_files/histarules_desde_primer_contrato.csv",
quote = FALSE,
sep = "|",
dec = ",",
row.names = TRUE,
col.names = NA
)
install.packages("markdown")
tinytex::install_tinytex()
q(0.95,171,11)
qnorm(0.95,171,11)
qnorm(0.95,171,11,FALSE,FALSE)
qt(.95,400)
qt(.025,400)
qt(.025,100)
qt(.024,100)
qt(.04,100)
qt(.004,100)
5
> qt(.025,400)
qt(.025,400)
qt(.05,400)
qt(.005,400)
qt(.5,100)
qt(0.05,100)
qt(0.95,100)
abs(qt(0.05, 100)) # 99% confidence, 1 sided (same as qt(0.99, 40))
abs(qt(0.05/2, 100)) # 99% confidence, 1 sided (same as qt(0.99, 40))
abs(qt((1-0.95)/2, 100)) # 99% confidence, 1 sided (same as qt(0.99, 40))
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
getwd
getwd()
setwd("C:\Users\PCI04\Desktop\Máster UOC\Est. Avanzada\A2 - Análisis estadístico I\Code")
setwd("C:/Users/PCI04/Desktop/Máster UOC/Est. Avanzada\A2 - Análisis estadístico I/Code")
setwd("C:/Users/PCI04/Desktop/Máster UOC/Est. Avanzada\A2 - Análisis estadístico I/")
setwd("C:\Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/")
setwd("C:\Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/")
setwd("C:\\Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/")
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
source('C:/Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/melchorgonzalez_analisisestadistico.R')
setwd("C:\\Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/")
childCarSeats_clean_filename <- "../Data/ChildCarSeats_clean.csv"
childCarSeats_clean <- read.csv(file=childCarSeats_clean_filename, header=TRUE, sep=",", na.strings=c(""," ","NA"))
head(childCarSeats_clean)
str(childCarSeats_clean)
childCarSeats_clean$ShelveLoc <- as.factor(childCarSeats_clean$ShelveLoc)
childCarSeats_clean$Urban <- as.factor(childCarSeats_clean$Urban)
childCarSeats_clean$US <- as.factor(childCarSeats_clean$US)
str(childCarSeats_clean)
dim(childCarSeats_clean)[1]
abs(qt((1-0.95)/2, 100))
abs(qt((1-0.95)/2,dim(childCarSeats_clean)[1]-1 ))
abs(qt((1-0.95)/2,dim(399 ))
source('C:/Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/melchorgonzalez_analisisestadistico.R')
abs(qt((1-0.95)/2,dim(399 )))
abs(qt((1-0.95)/2,dim(399)))
abs(qt((1-0.95)/2,(399)))
abs(qt((1-0.95)/2,dim(childCarSeats_clean)[1]-1 ))
sd(childCarSeats_clean$Sales)
s = sd(childCarSeats_clean$Sales)
sqrt(100)
n = dim(childCarSeats_clean)[1]
s = sd(childCarSeats_clean$Sales)
n
me = abs(qt((1-0.95)/2,n-1 )) * (s/sqrt(n))
me
mean(childCarSeats_clean$Sales)
x = mean(childCarSeats_clean$Sales)
x - me
x + me
confidenceInterval = c(x-me,x+me)
confidenceInterval
me
qnorm(0.95)*s/sqrt(n)
qnorm(0.95)*s/sqrt(n-1)
qnorm(0.95)*s/sqrt(n)
qnorm(0.95)*s/sqrt(n)
abs(qt((1-0.95)/2,n-1 ))
qnorm(0.95)*s/sqrt(n)
qnorm(0.95)
qnorm(0.95)
library(Rmisc)
library(Rmisc)
install.packages("Rmisc")
library(Rmisc)
CI(childCarSeats_clean$Sales, ci=0.95)
confidenceInterval
source('C:/Users/PCI04/Desktop/Máster UOC/Est. Avanzada/A2 - Análisis estadístico I/Code/melchorgonzalez_analisisestadistico.R')
